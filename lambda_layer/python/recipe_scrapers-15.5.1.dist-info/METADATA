Metadata-Version: 2.2
Name: recipe_scrapers
Version: 15.5.1
Summary: Python package, scraping recipes from all over the internet
Author-email: Hristo Harsev <r+pypi@hharsev.com>, James Addison <james@reciperadar.com>
Maintainer-email: Hristo Harsev <r+pypi@hharsev.com>, James Addison <james@reciperadar.com>
License: MIT License
Project-URL: Homepage, https://github.com/hhursev/recipe-scrapers/
Keywords: python,recipes,scraper,harvest,recipe-scraper,recipe-scrapers
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: License :: OSI Approved :: MIT License
Classifier: Intended Audience :: Developers
Classifier: Operating System :: OS Independent
Classifier: Topic :: Internet :: WWW/HTTP
Classifier: Topic :: Software Development :: Libraries
Requires-Python: >=3.9
Description-Content-Type: text/x-rst
License-File: LICENSE
Requires-Dist: beautifulsoup4>=4.12.3
Requires-Dist: extruct>=0.17.0
Requires-Dist: isodate>=0.6.1
Provides-Extra: online
Requires-Dist: requests>=2.31.0; extra == "online"
Provides-Extra: docs
Requires-Dist: mkdocs>=1.6.1; extra == "docs"
Requires-Dist: mkdocs-material>=9.5.48; extra == "docs"
Requires-Dist: mkdocstrings>=0.27.0; extra == "docs"
Requires-Dist: mkdocstrings-python>=1.12.2; extra == "docs"
Requires-Dist: markdown-exec>=1.10.0; extra == "docs"
Provides-Extra: tests
Requires-Dist: coverage>=7.6.9; extra == "tests"
Requires-Dist: unittest-parallel>=1.7.0; extra == "tests"
Provides-Extra: linters
Requires-Dist: pre-commit==4.0.1; extra == "linters"
Requires-Dist: black==24.10.0; extra == "linters"
Requires-Dist: flake8==7.1.1; extra == "linters"
Requires-Dist: pep8-naming==0.14.1; extra == "linters"
Requires-Dist: mypy==1.14.0; extra == "linters"
Requires-Dist: types-beautifulsoup4; extra == "linters"
Requires-Dist: types-requests; extra == "linters"
Provides-Extra: dev
Requires-Dist: recipe-scrapers[docs,linters,tests]; extra == "dev"
Provides-Extra: all
Requires-Dist: recipe_scrapers[dev,docs,linters,online,tests]; extra == "all"

=================
recipe-scrapers
=================

.. image:: https://img.shields.io/github/stars/hhursev/recipe-scrapers?style=social
    :target: https://github.com/hhursev/recipe-scrapers/
    :alt: Github
.. image:: https://img.shields.io/pypi/v/recipe-scrapers.svg?
    :target: https://pypi.org/project/recipe-scrapers/
    :alt: Version
.. image:: https://img.shields.io/pypi/pyversions/recipe-scrapers
    :target: https://pypi.org/project/recipe-scrapers/
    :alt: PyPI - Python Version
.. image:: https://github.com/hhursev/recipe-scrapers/actions/workflows/unittests.yaml/badge.svg?branch=main
    :target: unittests
    :alt: GitHub Actions Unittests
.. image:: https://coveralls.io/repos/hhursev/recipe-scraper/badge.svg?branch=main&service=github
    :target: https://coveralls.io/github/hhursev/recipe-scraper?branch=main
    :alt: Coveralls
.. image:: https://img.shields.io/github/license/hhursev/recipe-scrapers?
    :target: https://github.com/hhursev/recipe-scrapers/blob/main/LICENSE
    :alt: License


Quick Links
-----------
- `Documentation <https://docs.recipe-scrapers.com>`_
- `Supported Sites <https://docs.recipe-scrapers.com/getting-started/supported-sites/>`_
- `Contributing Guide <https://docs.recipe-scrapers.com/contributing/home/>`_
- `Issue Tracker <https://github.com/hhursev/recipe-scrapers/issues>`_
- `Share Project Ideas <https://github.com/hhursev/recipe-scrapers/issues/9>`_


A Python package for extracting recipe data from cooking websites. Parses recipe information from
either standard `HTML <https://developer.mozilla.org/en-US/docs/Web/HTML>`_ structure,
`Schema <https://schema.org/>`_ markup (including JSON-LD, Microdata, and RDFa formats) or
`OpenGraph <https://ogp.me/>`_ metadata.

The package provides a simple and consistent API for retrieving data such as ingredients, instructions,
cooking times, and more.

Compatible with the Python versions listed above. This package does not circumvent or bypass any
bot protection measures implemented by websites.


Installation
------------
.. code:: shell

    pip install recipe-scrapers


Basic Usage
-----------
.. code:: python

    from recipe_scrapers import scrape_me

    scraper = scrape_me("https://www.allrecipes.com/recipe/158968/spinach-and-feta-turkey-burgers/")
    scraper.title()
    scraper.instructions()
    scraper.to_json()
    # for a complete list of methods:
    # help(scraper)


This package is focused **exclusively on HTML parsing**.

For advanced implementations, you'll need to implement your own solution for fetching recipe HTMLs
and managing network requests. The library works best when you provide both the HTML content and
its source domain.

You are encouraged to use our *scrape_html* method:

.. code:: python

    from recipe_scrapers import scrape_html


Supported Sites
---------------
We support a wide range of recipe websites out of the box. Check our
`supported sites list <https://docs.recipe-scrapers.com/getting-started/supported-sites/>`_
for the full list.

You can also get the full list programmatically with:

.. code:: python

    from recipe_scrapers import SCRAPERS

    SCRAPERS.keys()


Contributing
------------
We welcome contributions! Please read our
`contribution guide <https://docs.recipe-scrapers.com/contributing/home/>`_ to get started.


Special Thanks
--------------
To all the `contributors <https://github.com/hhursev/recipe-scrapers/graphs/contributors>`_ who
help make this project better!

.. image:: https://contrib.rocks/image?repo=hhursev/recipe-scrapers
   :target: https://github.com/hhursev/recipe-scrapers/graphs/contributors


Share Your Project
------------------
Have an idea for using recipe-scrapers? Check out
our `project ideas wall <https://github.com/hhursev/recipe-scrapers/issues/9>`_ for inspiration
or to share your own project!
